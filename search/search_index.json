{
    "docs": [
        {
            "location": "/", 
            "text": "Siddhi-io-prometheus\n\n\nThe \nsiddhi-io-prometheus extension\n is an extension to \nSiddhi\n. The Prometheus-sink publishes Siddhi events as Prometheus metrics and expose them to Prometheus \nserver. The Prometheus-source retrieves Prometheus metrics from an endpoint and send them as \nSiddhi events.\n\n\nPrerequisites\n\n\n\n\nPrometheus server instance should be started.\n\n\nPrometheus Pushgateway should be started. (optional)\n\n\n\n\nFind some useful links below:\n\n \nSource code\n\n\n \nReleases\n\n* \nIssue tracker\n\n\nLatest API Docs\n\n\nLatest API Docs is \n1.0.1\n.\n\n\nHow to use\n\n\nUsing the extension in \nWSO2 Stream Processor\n\n\n\n\n\n\nYou can use this extension in the latest \nWSO2 Stream Processor\n that is a part of \nWSO2 Analytics\n offering, with editor, debugger and simulation support.\n\n\n\n\n\n\nThis extension is shipped by default with WSO2 Stream Processor, if you wish to use an alternative version of this extension you can replace the component \njar\n that can be found in the \nSTREAM_PROCESSOR_HOME\n/lib\n directory.\n\n\n\n\n\n\nUsing the extension as a \njava library\n\n\n\n\nThis extension can be added as a maven dependency along with other Siddhi dependencies to your project.\n\n\n\n\n     \ndependency\n\n        \ngroupId\norg.wso2.extension.siddhi.io.prometheus\n/groupId\n\n        \nartifactId\nsiddhi-io-prometheus\n/artifactId\n\n        \nversion\nx.x.x\n/version\n\n     \n/dependency\n\n\n\n\n\n\nJenkins Build Status\n\n\n\n\n\n\n\n\n\n\nBranch\n\n\nBuild Status\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n\n\n\n\n\n\n\n\n\n\nFeatures\n\n\n\n\nprometheus\n \n(Sink)\nThe sink publishes events processed by Siddhi into Prometheus metrics and exposes them to Prometheus server at the provided url. The created metrics can be published to Prometheus through 'server' or 'pushGateway' publishing modes depending on the preference of the user. The server mode exposes the metrics through an http server at the provided url and the pushGateway mode pushes the metrics to pushGateway which must be running at the provided url.\nThe metric types that are supported by Prometheus sink are counter, gauge, histogram and summary. The values and labels of the Prometheus metrics can be updated through the events. \n\n\nprometheus\n \n(Source)\nThe source consumes Prometheus metrics which are exported from the specified url as Siddhi events, by making http requests to the url. According to the source configuration, it analyses metrics from the text response and sends them as Siddhi events through key-value mapping.The user can retrieve metrics of types including, counter, gauge, histogram and summary. Since the source retrieves the metrics from a text response of the target, it is advised to use 'string' as the attribute type for the attributes that correspond to Prometheus metric labels. Further, the Prometheus metric value is passed through the event as 'value'. Therefore, it is advisable to have an attribute with the name 'value' in the stream. \nThe supported types for the attribute, 'value' are INT, LONG, FLOAT and DOUBLE.\n\n\n\n\nHow to contribute\n\n\n\n\n\n\nReport issues at \nGitHub Issue Tracker\n.\n\n\n\n\n\n\nSend your contributions as pull requests to the \nmaster branch\n.\n\n\n\n\n\n\nRunning Integration tests in docker containers (Optional)\n\n\n\n\nThe prometheus sink can be tested with the docker base integration test framework. The test framework initialize a docker container with required configuration before execute the test suit.\n\n\n\n\nTo start integration tests,\n\n\n 1. Install and run docker\n\n 2. To run the integration tests,\n\n     - navigate to the siddhi-io-prometheus/ directory and issue the following command.\n       ```\n       mvn verify -P local-prometheus\n       ```\n\n\n\n\n\n\n\n\n\nPrometheus target configurations can be modified at the directory for integration tests : \n\n\nsiddhi-io-prometheus/component/src/test/resources/prometheus/prometheus.yml\n\n\n\n\n\n\nContact us\n\n\n\n\n\n\nPost your questions with the \n\"Siddhi\"\n tag in \nStackoverflow\n.\n\n\n\n\n\n\nSiddhi developers can be contacted via the mailing lists:\n\n\nDevelopers List   : \ndev@wso2.org\n\n\nArchitecture List : \narchitecture@wso2.org\n\n\n\n\n\n\nSupport\n\n\n\n\n\n\nWe are committed to ensuring support for this extension in production. Our unique approach ensures that all support leverages our open development methodology and is provided by the very same engineers who build the technology.\n\n\n\n\n\n\nFor more details and to take advantage of this unique opportunity contact us via \nhttp://wso2.com/support/\n.", 
            "title": "Welcome to WSO2 Siddhi IO Prometheus"
        }, 
        {
            "location": "/#siddhi-io-prometheus", 
            "text": "The  siddhi-io-prometheus extension  is an extension to  Siddhi . The Prometheus-sink publishes Siddhi events as Prometheus metrics and expose them to Prometheus \nserver. The Prometheus-source retrieves Prometheus metrics from an endpoint and send them as \nSiddhi events.", 
            "title": "Siddhi-io-prometheus"
        }, 
        {
            "location": "/#prerequisites", 
            "text": "Prometheus server instance should be started.  Prometheus Pushgateway should be started. (optional)   Find some useful links below:   Source code    Releases \n*  Issue tracker", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/#latest-api-docs", 
            "text": "Latest API Docs is  1.0.1 .", 
            "title": "Latest API Docs"
        }, 
        {
            "location": "/#how-to-use", 
            "text": "Using the extension in  WSO2 Stream Processor    You can use this extension in the latest  WSO2 Stream Processor  that is a part of  WSO2 Analytics  offering, with editor, debugger and simulation support.    This extension is shipped by default with WSO2 Stream Processor, if you wish to use an alternative version of this extension you can replace the component  jar  that can be found in the  STREAM_PROCESSOR_HOME /lib  directory.    Using the extension as a  java library   This extension can be added as a maven dependency along with other Siddhi dependencies to your project.         dependency \n         groupId org.wso2.extension.siddhi.io.prometheus /groupId \n         artifactId siddhi-io-prometheus /artifactId \n         version x.x.x /version \n      /dependency", 
            "title": "How to use"
        }, 
        {
            "location": "/#jenkins-build-status", 
            "text": "Branch  Build Status      master", 
            "title": "Jenkins Build Status"
        }, 
        {
            "location": "/#features", 
            "text": "prometheus   (Sink) The sink publishes events processed by Siddhi into Prometheus metrics and exposes them to Prometheus server at the provided url. The created metrics can be published to Prometheus through 'server' or 'pushGateway' publishing modes depending on the preference of the user. The server mode exposes the metrics through an http server at the provided url and the pushGateway mode pushes the metrics to pushGateway which must be running at the provided url. The metric types that are supported by Prometheus sink are counter, gauge, histogram and summary. The values and labels of the Prometheus metrics can be updated through the events.   prometheus   (Source) The source consumes Prometheus metrics which are exported from the specified url as Siddhi events, by making http requests to the url. According to the source configuration, it analyses metrics from the text response and sends them as Siddhi events through key-value mapping.The user can retrieve metrics of types including, counter, gauge, histogram and summary. Since the source retrieves the metrics from a text response of the target, it is advised to use 'string' as the attribute type for the attributes that correspond to Prometheus metric labels. Further, the Prometheus metric value is passed through the event as 'value'. Therefore, it is advisable to have an attribute with the name 'value' in the stream.  The supported types for the attribute, 'value' are INT, LONG, FLOAT and DOUBLE.", 
            "title": "Features"
        }, 
        {
            "location": "/#how-to-contribute", 
            "text": "Report issues at  GitHub Issue Tracker .    Send your contributions as pull requests to the  master branch .", 
            "title": "How to contribute"
        }, 
        {
            "location": "/#running-integration-tests-in-docker-containers-optional", 
            "text": "The prometheus sink can be tested with the docker base integration test framework. The test framework initialize a docker container with required configuration before execute the test suit.   To start integration tests,   1. Install and run docker\n\n 2. To run the integration tests,\n\n     - navigate to the siddhi-io-prometheus/ directory and issue the following command.\n       ```\n       mvn verify -P local-prometheus\n       ```    Prometheus target configurations can be modified at the directory for integration tests :   siddhi-io-prometheus/component/src/test/resources/prometheus/prometheus.yml", 
            "title": "Running Integration tests in docker containers (Optional)"
        }, 
        {
            "location": "/#contact-us", 
            "text": "Post your questions with the  \"Siddhi\"  tag in  Stackoverflow .    Siddhi developers can be contacted via the mailing lists:  Developers List   :  dev@wso2.org  Architecture List :  architecture@wso2.org", 
            "title": "Contact us"
        }, 
        {
            "location": "/#support", 
            "text": "We are committed to ensuring support for this extension in production. Our unique approach ensures that all support leverages our open development methodology and is provided by the very same engineers who build the technology.    For more details and to take advantage of this unique opportunity contact us via  http://wso2.com/support/ .", 
            "title": "Support"
        }, 
        {
            "location": "/api/1.0.1/", 
            "text": "API Docs - v1.0.1\n\n\nSink\n\n\nprometheus \n(Sink)\n\n\nThe sink publishes events processed by Siddhi into Prometheus metrics and exposes them to Prometheus server at the provided url. The created metrics can be published to Prometheus through 'server' or 'pushGateway' publishing modes depending on the preference of the user. The server mode exposes the metrics through an http server at the provided url and the pushGateway mode pushes the metrics to pushGateway which must be running at the provided url.\nThe metric types that are supported by Prometheus sink are counter, gauge, histogram and summary. The values and labels of the Prometheus metrics can be updated through the events. \n\n\n\nSyntax\n\n\n@sink(type=\nprometheus\n, job=\nSTRING\n, publish.mode=\nSTRING\n, push.url=\nSTRING\n, server.url=\nSTRING\n, metric.type=\nSTRING\n, metric.help=\nSTRING\n, metric.name=\nSTRING\n, buckets=\nSTRING\n, quantiles=\nSTRING\n, quantile.error=\nDOUBLE\n, value.attribute=\nSTRING\n, push.operation=\nSTRING\n, grouping.key=\nSTRING\n, @map(...)))\n\n\n\n\n\nQUERY PARAMETERS\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Data Types\n\n        \nOptional\n\n        \nDynamic\n\n    \n\n    \n\n        \njob\n\n        \nThis parameter specifies the job name of the metric. The name must be the same job name as defined in the prometheus configuration file.\n\n        \nsiddhiJob\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npublish.mode\n\n        \nThis parameter specifies the mode of exposing metrics to Prometheus server.The possible publishing modes are 'server' and 'pushgateway'.\n\n        \nserver\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npush.url\n\n        \nThis parameter specifies the target url of the Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target.\n\n        \nhttp://localhost:9091\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nserver.url\n\n        \nThis parameter specifies the url where the http server is initiated to expose metrics for 'server' publish mode. This url must be previously defined in prometheus configuration file as a target.\n\n        \nhttp://localhost:9080\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.type\n\n        \nThe type of Prometheus metric that has to be created at the sink.\nThe supported metric types are 'counter', 'gauge', 'histogram' and 'summary'. \n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.help\n\n        \nA brief description of the metric and its purpose.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.name\n\n        \nThis parameter specifies the user preferred name for the metric. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]*. \n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nbuckets\n\n        \nThe bucket values preferred by the user for histogram metrics. The bucket values must be in 'string' format with each bucket value separated by a comma.\nThe expected format of the parameter is as follows: \n\"2,4,6,8\"\n\n        \nnull\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nquantiles\n\n        \nThe user preferred quantile values for summary metrics. The quantile values must be in 'string' format with each quantile value separated by a comma.\nThe expected format of the parameter is as follows: \n\"0.5,0.75,0.95\"\n\n        \nnull\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nquantile.error\n\n        \nThe error tolerance value for calculating quantiles in summary metrics. This must be a positive value though less than 1.\n\n        \n0.001\n\n        \nDOUBLE\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nvalue.attribute\n\n        \nThe name of the attribute in stream definition which specifies the metric value. The defined value attribute must be included inside the stream attributes. The value of the 'value' attribute that is published through events, increase the metric value for the counter and gauge metric types. For histogram and summary metric types, the values are observed.\n\n        \nvalue\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npush.operation\n\n        \nThis parameter defines the mode for pushing metrics to pushGateway The available push operations are 'push' and 'pushadd'. The operations differ according to the existing metrics in pushGateway where 'push' operation replaces the existing metrics and 'pushadd' operation only updates the newly created metrics.\n\n        \npushadd\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ngrouping.key\n\n        \nThis parameter specifies the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics. \nThe expected format of the grouping key is as follows:\n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n\n\n\nSystem Parameters\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Parameters\n\n    \n\n    \n\n        \njobName\n\n        \nThis is the property that specifies the default job name for the metric. The name must be the same job name as defined in the prometheus configuration file.\n\n        \nsiddhiJob\n\n        \nAny string\n\n    \n\n    \n\n        \npublishMode\n\n        \nThe default publish mode for the Prometheus sink for exposing metrics to Prometheus server. The mode can be either 'server' or 'pushgateway'. \n\n        \nserver\n\n        \nserver or pushgateway\n\n    \n\n    \n\n        \nserverURL\n\n        \nThis property configures the url where the http server will be initiated to expose metrics. This url must be previously defined in prometheus configuration file as a target to be identified by Prometheus. By default, the http server will be initiated at 'http://localhost:9080'\n\n        \nhttp://localhost:9080\n\n        \nAny valid URL\n\n    \n\n    \n\n        \npushURL\n\n        \nThis property configures the target url of Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target to be identified by Prometheus.\n\n        \nhttp://localhost:9091\n\n        \nAny valid URL\n\n    \n\n    \n\n        \ngroupingKey\n\n        \nThis property configures the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics under same job. The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" .\n\n        \nnull\n\n        \nAny key value pairs in the supported format\n\n    \n\n\n\n\nExamples\n\n\nEXAMPLE 1\n\n\n@sink(type=\nprometheus\n,job=\nfooOrderCount\n, server.url =\nhttp://localhost:9080\n, publish.mode=\nserver\n, metric.type=\ncounter\n, metric.help= \nNumber of foo orders\n, @map(type=\nkeyvalue\n))\ndefine stream FooCountStream (Name String, quantity int, value int);\n\n\n\n\n\n In the above example, the Prometheus-sink creates a counter metric with the stream name and defined attributes as labels. The metric is exposed through an http server at the target url.\n\n\n\nEXAMPLE 2\n\n\n@sink(type=\nprometheus\n,job=\ninventoryLevel\n, push.url=\nhttp://localhost:9080\n, publish.mode=\npushGateway\n, metric.type=\ngauge\n, metric.help= \nCurrent level of inventory\n, @map(type=\nkeyvalue\n))\ndefine stream InventoryLevelStream (Name String, value int);\n\n\n\n\n\n In the above example, the Prometheus-sink creates a gauge metric with the stream name and defined attributes as labels.The metric is pushed to Prometheus pushGateway at the target url.\n\n\n\nSource\n\n\nprometheus \n(Source)\n\n\nThe source consumes Prometheus metrics which are exported from the specified url as Siddhi events, by making http requests to the url. According to the source configuration, it analyses metrics from the text response and sends them as Siddhi events through key-value mapping.The user can retrieve metrics of types including, counter, gauge, histogram and summary. Since the source retrieves the metrics from a text response of the target, it is advised to use 'string' as the attribute type for the attributes that correspond to Prometheus metric labels. Further, the Prometheus metric value is passed through the event as 'value'. Therefore, it is advisable to have an attribute with the name 'value' in the stream. \nThe supported types for the attribute, 'value' are INT, LONG, FLOAT and DOUBLE.\n\n\n\nSyntax\n\n\n@source(type=\nprometheus\n, target.url=\nSTRING\n, scrape.interval=\nINT\n, scrape.timeout=\nINT\n, scheme=\nSTRING\n, metric.name=\nSTRING\n, metric.type=\nSTRING\n, username=\nSTRING\n, password=\nSTRING\n, client.truststore.file=\nSTRING\n, client.truststore.password=\nSTRING\n, headers=\nSTRING\n, job=\nSTRING\n, instance=\nSTRING\n, grouping.key=\nSTRING\n, @map(...)))\n\n\n\n\n\nQUERY PARAMETERS\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Data Types\n\n        \nOptional\n\n        \nDynamic\n\n    \n\n    \n\n        \ntarget.url\n\n        \nThis property specifies the target url where the Prometheus metrics are exported in text format.\n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nscrape.interval\n\n        \nThis property specifies the time interval in seconds within which the source should make an HTTP request to the  provided target url.\n\n        \n60\n\n        \nINT\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nscrape.timeout\n\n        \nThis property is the time duration in seconds for a scrape request to get timed-out if the server at the url does not respond.\n\n        \n10\n\n        \nINT\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nscheme\n\n        \nThis property specifies the scheme of the target URL.\nThe supported schemes are 'HTTP' and 'HTTPS'.\n\n        \nHTTP\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.name\n\n        \nThis property specifies the name of the metrics that are to be fetched. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]* .\n\n        \nStream name\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.type\n\n        \nThis property specifies the type of the Prometheus metric that is required to be fetched. \nThe supported metric types are 'counter', 'gauge',\" 'histogram' and 'summary'. \n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nusername\n\n        \nThis property specifies the username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npassword\n\n        \nThis property specifies the password that has to be added in the authorization header of the request, if the basic authentication is enabled at the target. It is required to specify both the username and password to enable basic authentication. If one of the parameter is not given by user, then an error is logged in the console.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nclient.truststore.file\n\n        \nThe file path to the location of the truststore to which the client needs to send https requests through 'https' protocol.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nclient.truststore.password\n\n        \n The password for client-truststore to send https requests. A custom password can be specified if required. \n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nheaders\n\n        \nHeaders that should be included as HTTP request headers in the request. \nThe format of the supported input is as follows, \n\"'header1:value1','header2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \njob\n\n        \n This property defines the job name of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ninstance\n\n        \nThis property defines the instance of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ngrouping.key\n\n        \nThis parameter specifies the grouping key of the required metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics.\nThe expected format of the grouping key is as follows: \n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n\n\n\nSystem Parameters\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Parameters\n\n    \n\n    \n\n        \nscrapeInterval\n\n        \nThe default time interval in seconds for the Prometheus source to make HTTP requests to the target URL.\n\n        \n60\n\n        \nAny integer value\n\n    \n\n    \n\n        \nscrapeTimeout\n\n        \nThis default time duration (in seconds) for an HTTP request to time-out if the server at the URL does not respond. \n\n        \n10\n\n        \nAny integer value\n\n    \n\n    \n\n        \nscheme\n\n        \nThe scheme of the target for Prometheus source to make HTTP requests. The supported schemes are HTTP and HTTPS.\n\n        \nHTTP\n\n        \nHTTP or HTTPS\n\n    \n\n    \n\n        \nusername\n\n        \nThe username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nAny string\n\n    \n\n    \n\n        \npassword\n\n        \nThe password that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nAny string\n\n    \n\n    \n\n        \ntrustStoreFile\n\n        \nThe default file path to the location of truststore that the client needs to send for HTTPS requests through 'HTTPS' protocol.\n\n        \n${carbon.home}/resources/security/client-truststore.jks\n\n        \nAny valid path for the truststore file\n\n    \n\n    \n\n        \ntrustStorePassword\n\n        \nThe default password for the client-truststore to send HTTPS requests.\n\n        \nwso2carbon\n\n        \nAny string\n\n    \n\n    \n\n        \nheaders\n\n        \nThe headers that should be included as HTTP request headers in the scrape request. \nThe format of the supported input is as follows, \n\"'header1:value1','header2:value2'\"\n\n        \n\n        \nAny valid http headers\n\n    \n\n    \n\n        \njob\n\n        \n The default job name of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nAny valid job name\n\n    \n\n    \n\n        \ninstance\n\n        \nThe default instance of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nAny valid instance name\n\n    \n\n    \n\n        \ngroupingKey\n\n        \nThe default grouping key of the required Prometheus metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics. \nThe expected format of the grouping key is as follows: \n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nAny valid grouping key pairs\n\n    \n\n\n\n\nExamples\n\n\nEXAMPLE 1\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \ncounter\n, metric.name= \nsweet_production_counter\n, @map(type= \nkeyvalue\n))\ndefine stream FooStream1(metric_name string, metric_type string, help string, subtype string, name string, quantity string, value double);\n\n\n\n\n\nIn this example, the prometheus source makes an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus counter metrics with the name, 'sweet_production_counter' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps will have keys and values as follows: \nmetric_name  -\n sweet_production_counter\nmetric_type  -\n counter\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n null\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nvalue -\n \nvalue_of_metric\n\n\n\nEXAMPLE 2\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \nsummary\n, metric.name= \nsweet_production_summary\n, @map(type= \nkeyvalue\n))\n define stream FooStream2(metric_name string, metric_type string, help string, subtype string, name string, quantity string, quantile string, value double);\n\n\n\n\n\nIn this example, the prometheus source makes an http request to the 'target.url' and analyses the response. From the analysed response, the source retrieves the Prometheus summary metrics with the name, 'sweet_production_summary' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps have keys and values as follows: \nmetric_name  -\n sweet_production_summary\nmetric_type  -\n summary\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n \n'sum'/'count'/'null'\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nquantile  -\n \nvalue of the quantile\nvalue -\n \nvalue_of_metric\n\n\n\nEXAMPLE 3\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \nhistogram\n, metric.name= \nsweet_production_histogram\n, @map(type= \nkeyvalue\n))\ndefine stream FooStream3(metric_name string, metric_type string, help string, subtype string, name string, quantity string, le string, value double);\n\n\n\n\n\nIn this example, the prometheus source will make an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus histogram metrics with name 'sweet_production_histogram' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps will have keys and values as follows, \nmetric_name  -\n sweet_production_histogram\nmetric_type  -\n histogram\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n \n'sum'/'count'/'bucket'\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nle  -\n \nvalue of the bucket\nvalue -\n \nvalue_of_metric", 
            "title": "1.0.1"
        }, 
        {
            "location": "/api/1.0.1/#api-docs-v101", 
            "text": "", 
            "title": "API Docs - v1.0.1"
        }, 
        {
            "location": "/api/1.0.1/#sink", 
            "text": "", 
            "title": "Sink"
        }, 
        {
            "location": "/api/1.0.1/#prometheus-sink", 
            "text": "The sink publishes events processed by Siddhi into Prometheus metrics and exposes them to Prometheus server at the provided url. The created metrics can be published to Prometheus through 'server' or 'pushGateway' publishing modes depending on the preference of the user. The server mode exposes the metrics through an http server at the provided url and the pushGateway mode pushes the metrics to pushGateway which must be running at the provided url. The metric types that are supported by Prometheus sink are counter, gauge, histogram and summary. The values and labels of the Prometheus metrics can be updated through the events.   Syntax  @sink(type= prometheus , job= STRING , publish.mode= STRING , push.url= STRING , server.url= STRING , metric.type= STRING , metric.help= STRING , metric.name= STRING , buckets= STRING , quantiles= STRING , quantile.error= DOUBLE , value.attribute= STRING , push.operation= STRING , grouping.key= STRING , @map(...)))  QUERY PARAMETERS  \n     \n         Name \n         Description \n         Default Value \n         Possible Data Types \n         Optional \n         Dynamic \n     \n     \n         job \n         This parameter specifies the job name of the metric. The name must be the same job name as defined in the prometheus configuration file. \n         siddhiJob \n         STRING \n         Yes \n         No \n     \n     \n         publish.mode \n         This parameter specifies the mode of exposing metrics to Prometheus server.The possible publishing modes are 'server' and 'pushgateway'. \n         server \n         STRING \n         Yes \n         No \n     \n     \n         push.url \n         This parameter specifies the target url of the Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target. \n         http://localhost:9091 \n         STRING \n         Yes \n         No \n     \n     \n         server.url \n         This parameter specifies the url where the http server is initiated to expose metrics for 'server' publish mode. This url must be previously defined in prometheus configuration file as a target. \n         http://localhost:9080 \n         STRING \n         Yes \n         No \n     \n     \n         metric.type \n         The type of Prometheus metric that has to be created at the sink. The supported metric types are 'counter', 'gauge', 'histogram' and 'summary'.  \n         \n         STRING \n         No \n         No \n     \n     \n         metric.help \n         A brief description of the metric and its purpose. \n         \n         STRING \n         Yes \n         No \n     \n     \n         metric.name \n         This parameter specifies the user preferred name for the metric. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]*.  \n         \n         STRING \n         Yes \n         No \n     \n     \n         buckets \n         The bucket values preferred by the user for histogram metrics. The bucket values must be in 'string' format with each bucket value separated by a comma. The expected format of the parameter is as follows:  \"2,4,6,8\" \n         null \n         STRING \n         Yes \n         No \n     \n     \n         quantiles \n         The user preferred quantile values for summary metrics. The quantile values must be in 'string' format with each quantile value separated by a comma. The expected format of the parameter is as follows:  \"0.5,0.75,0.95\" \n         null \n         STRING \n         Yes \n         No \n     \n     \n         quantile.error \n         The error tolerance value for calculating quantiles in summary metrics. This must be a positive value though less than 1. \n         0.001 \n         DOUBLE \n         Yes \n         No \n     \n     \n         value.attribute \n         The name of the attribute in stream definition which specifies the metric value. The defined value attribute must be included inside the stream attributes. The value of the 'value' attribute that is published through events, increase the metric value for the counter and gauge metric types. For histogram and summary metric types, the values are observed. \n         value \n         STRING \n         Yes \n         No \n     \n     \n         push.operation \n         This parameter defines the mode for pushing metrics to pushGateway The available push operations are 'push' and 'pushadd'. The operations differ according to the existing metrics in pushGateway where 'push' operation replaces the existing metrics and 'pushadd' operation only updates the newly created metrics. \n         pushadd \n         STRING \n         Yes \n         No \n     \n     \n         grouping.key \n         This parameter specifies the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics.  The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" \n         \n         STRING \n         Yes \n         No \n       System Parameters  \n     \n         Name \n         Description \n         Default Value \n         Possible Parameters \n     \n     \n         jobName \n         This is the property that specifies the default job name for the metric. The name must be the same job name as defined in the prometheus configuration file. \n         siddhiJob \n         Any string \n     \n     \n         publishMode \n         The default publish mode for the Prometheus sink for exposing metrics to Prometheus server. The mode can be either 'server' or 'pushgateway'.  \n         server \n         server or pushgateway \n     \n     \n         serverURL \n         This property configures the url where the http server will be initiated to expose metrics. This url must be previously defined in prometheus configuration file as a target to be identified by Prometheus. By default, the http server will be initiated at 'http://localhost:9080' \n         http://localhost:9080 \n         Any valid URL \n     \n     \n         pushURL \n         This property configures the target url of Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target to be identified by Prometheus. \n         http://localhost:9091 \n         Any valid URL \n     \n     \n         groupingKey \n         This property configures the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics under same job. The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" . \n         null \n         Any key value pairs in the supported format \n       Examples  EXAMPLE 1  @sink(type= prometheus ,job= fooOrderCount , server.url = http://localhost:9080 , publish.mode= server , metric.type= counter , metric.help=  Number of foo orders , @map(type= keyvalue ))\ndefine stream FooCountStream (Name String, quantity int, value int);   In the above example, the Prometheus-sink creates a counter metric with the stream name and defined attributes as labels. The metric is exposed through an http server at the target url.  EXAMPLE 2  @sink(type= prometheus ,job= inventoryLevel , push.url= http://localhost:9080 , publish.mode= pushGateway , metric.type= gauge , metric.help=  Current level of inventory , @map(type= keyvalue ))\ndefine stream InventoryLevelStream (Name String, value int);   In the above example, the Prometheus-sink creates a gauge metric with the stream name and defined attributes as labels.The metric is pushed to Prometheus pushGateway at the target url.", 
            "title": "prometheus (Sink)"
        }, 
        {
            "location": "/api/1.0.1/#source", 
            "text": "", 
            "title": "Source"
        }, 
        {
            "location": "/api/1.0.1/#prometheus-source", 
            "text": "The source consumes Prometheus metrics which are exported from the specified url as Siddhi events, by making http requests to the url. According to the source configuration, it analyses metrics from the text response and sends them as Siddhi events through key-value mapping.The user can retrieve metrics of types including, counter, gauge, histogram and summary. Since the source retrieves the metrics from a text response of the target, it is advised to use 'string' as the attribute type for the attributes that correspond to Prometheus metric labels. Further, the Prometheus metric value is passed through the event as 'value'. Therefore, it is advisable to have an attribute with the name 'value' in the stream.  The supported types for the attribute, 'value' are INT, LONG, FLOAT and DOUBLE.  Syntax  @source(type= prometheus , target.url= STRING , scrape.interval= INT , scrape.timeout= INT , scheme= STRING , metric.name= STRING , metric.type= STRING , username= STRING , password= STRING , client.truststore.file= STRING , client.truststore.password= STRING , headers= STRING , job= STRING , instance= STRING , grouping.key= STRING , @map(...)))  QUERY PARAMETERS  \n     \n         Name \n         Description \n         Default Value \n         Possible Data Types \n         Optional \n         Dynamic \n     \n     \n         target.url \n         This property specifies the target url where the Prometheus metrics are exported in text format. \n         \n         STRING \n         No \n         No \n     \n     \n         scrape.interval \n         This property specifies the time interval in seconds within which the source should make an HTTP request to the  provided target url. \n         60 \n         INT \n         Yes \n         No \n     \n     \n         scrape.timeout \n         This property is the time duration in seconds for a scrape request to get timed-out if the server at the url does not respond. \n         10 \n         INT \n         Yes \n         No \n     \n     \n         scheme \n         This property specifies the scheme of the target URL. The supported schemes are 'HTTP' and 'HTTPS'. \n         HTTP \n         STRING \n         Yes \n         No \n     \n     \n         metric.name \n         This property specifies the name of the metrics that are to be fetched. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]* . \n         Stream name \n         STRING \n         Yes \n         No \n     \n     \n         metric.type \n         This property specifies the type of the Prometheus metric that is required to be fetched.  The supported metric types are 'counter', 'gauge',\" 'histogram' and 'summary'.  \n         \n         STRING \n         No \n         No \n     \n     \n         username \n         This property specifies the username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         STRING \n         Yes \n         No \n     \n     \n         password \n         This property specifies the password that has to be added in the authorization header of the request, if the basic authentication is enabled at the target. It is required to specify both the username and password to enable basic authentication. If one of the parameter is not given by user, then an error is logged in the console. \n         \n         STRING \n         Yes \n         No \n     \n     \n         client.truststore.file \n         The file path to the location of the truststore to which the client needs to send https requests through 'https' protocol. \n         \n         STRING \n         Yes \n         No \n     \n     \n         client.truststore.password \n          The password for client-truststore to send https requests. A custom password can be specified if required.  \n         \n         STRING \n         Yes \n         No \n     \n     \n         headers \n         Headers that should be included as HTTP request headers in the request.  The format of the supported input is as follows,  \"'header1:value1','header2:value2'\" \n         \n         STRING \n         Yes \n         No \n     \n     \n         job \n          This property defines the job name of the exported Prometheus metrics that has to be fetched. \n         \n         STRING \n         Yes \n         No \n     \n     \n         instance \n         This property defines the instance of the exported Prometheus metrics that has to be fetched. \n         \n         STRING \n         Yes \n         No \n     \n     \n         grouping.key \n         This parameter specifies the grouping key of the required metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics. The expected format of the grouping key is as follows:  \"'key1:value1','key2:value2'\" \n         \n         STRING \n         Yes \n         No \n       System Parameters  \n     \n         Name \n         Description \n         Default Value \n         Possible Parameters \n     \n     \n         scrapeInterval \n         The default time interval in seconds for the Prometheus source to make HTTP requests to the target URL. \n         60 \n         Any integer value \n     \n     \n         scrapeTimeout \n         This default time duration (in seconds) for an HTTP request to time-out if the server at the URL does not respond.  \n         10 \n         Any integer value \n     \n     \n         scheme \n         The scheme of the target for Prometheus source to make HTTP requests. The supported schemes are HTTP and HTTPS. \n         HTTP \n         HTTP or HTTPS \n     \n     \n         username \n         The username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         Any string \n     \n     \n         password \n         The password that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         Any string \n     \n     \n         trustStoreFile \n         The default file path to the location of truststore that the client needs to send for HTTPS requests through 'HTTPS' protocol. \n         ${carbon.home}/resources/security/client-truststore.jks \n         Any valid path for the truststore file \n     \n     \n         trustStorePassword \n         The default password for the client-truststore to send HTTPS requests. \n         wso2carbon \n         Any string \n     \n     \n         headers \n         The headers that should be included as HTTP request headers in the scrape request.  The format of the supported input is as follows,  \"'header1:value1','header2:value2'\" \n         \n         Any valid http headers \n     \n     \n         job \n          The default job name of the exported Prometheus metrics that has to be fetched. \n         \n         Any valid job name \n     \n     \n         instance \n         The default instance of the exported Prometheus metrics that has to be fetched. \n         \n         Any valid instance name \n     \n     \n         groupingKey \n         The default grouping key of the required Prometheus metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics.  The expected format of the grouping key is as follows:  \"'key1:value1','key2:value2'\" \n         \n         Any valid grouping key pairs \n       Examples  EXAMPLE 1  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  counter , metric.name=  sweet_production_counter , @map(type=  keyvalue ))\ndefine stream FooStream1(metric_name string, metric_type string, help string, subtype string, name string, quantity string, value double);  In this example, the prometheus source makes an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus counter metrics with the name, 'sweet_production_counter' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps will have keys and values as follows:  metric_name  -  sweet_production_counter metric_type  -  counter help  -   help_string_of_metric subtype  -  null name -   value_of_label_name quantity -   value_of_label_quantity value -   value_of_metric  EXAMPLE 2  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  summary , metric.name=  sweet_production_summary , @map(type=  keyvalue ))\n define stream FooStream2(metric_name string, metric_type string, help string, subtype string, name string, quantity string, quantile string, value double);  In this example, the prometheus source makes an http request to the 'target.url' and analyses the response. From the analysed response, the source retrieves the Prometheus summary metrics with the name, 'sweet_production_summary' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps have keys and values as follows:  metric_name  -  sweet_production_summary metric_type  -  summary help  -   help_string_of_metric subtype  -   'sum'/'count'/'null' name -   value_of_label_name quantity -   value_of_label_quantity quantile  -   value of the quantile value -   value_of_metric  EXAMPLE 3  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  histogram , metric.name=  sweet_production_histogram , @map(type=  keyvalue ))\ndefine stream FooStream3(metric_name string, metric_type string, help string, subtype string, name string, quantity string, le string, value double);  In this example, the prometheus source will make an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus histogram metrics with name 'sweet_production_histogram' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps will have keys and values as follows,  metric_name  -  sweet_production_histogram metric_type  -  histogram help  -   help_string_of_metric subtype  -   'sum'/'count'/'bucket' name -   value_of_label_name quantity -   value_of_label_quantity le  -   value of the bucket value -   value_of_metric", 
            "title": "prometheus (Source)"
        }, 
        {
            "location": "/api/1.0.0/", 
            "text": "API Docs - v1.0.0\n\n\nSink\n\n\nprometheus \n(Sink)\n\n\nThe sink publishes events processed by WSO2 SP into Prometheus metrics and exposes them to Prometheus server at the provided url. The created metrics can be published to Prometheus through 'server' or 'pushGateway' publishing modes depending on the preference of the user. The server mode exposes the metrics through an http server at the provided url and the pushGateway mode pushes the metrics to pushGateway which must be running at the provided url.\nThe metric types that are supported by Prometheus sink are counter, gauge, histogram and summary. The values and labels of the Prometheus metrics can be updated through the events. \n\n\n\nSyntax\n\n\n@sink(type=\nprometheus\n, job=\nSTRING\n, publish.mode=\nSTRING\n, push.url=\nSTRING\n, server.url=\nSTRING\n, metric.type=\nSTRING\n, metric.help=\nSTRING\n, metric.name=\nSTRING\n, buckets=\nSTRING\n, quantiles=\nSTRING\n, quantile.error=\nDOUBLE\n, value.attribute=\nSTRING\n, push.operation=\nSTRING\n, grouping.key=\nSTRING\n, @map(...)))\n\n\n\n\n\nQUERY PARAMETERS\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Data Types\n\n        \nOptional\n\n        \nDynamic\n\n    \n\n    \n\n        \njob\n\n        \nThis parameter specifies the job name of the metric. The name must be the same job name as defined in the prometheus configuration file.\n\n        \nsiddhiJob\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npublish.mode\n\n        \nThis parameter specifies the mode of exposing metrics to Prometheus server.The possible publishing modes are 'server' and 'pushgateway'.\n\n        \nserver\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npush.url\n\n        \nThis parameter specifies the target url of the Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target.\n\n        \nhttp://localhost:9091\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nserver.url\n\n        \nThis parameter specifies the url where the http server is initiated to expose metrics for 'server' publish mode. This url must be previously defined in prometheus configuration file as a target.\n\n        \nhttp://localhost:9080\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.type\n\n        \nThe type of Prometheus metric that has to be created at the sink.\nThe supported metric types are 'counter', 'gauge', 'histogram' and 'summary'. \n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.help\n\n        \nA brief description of the metric and its purpose.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.name\n\n        \nThis parameter specifies the user preferred name for the metric. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]*. \n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nbuckets\n\n        \nThe bucket values preferred by the user for histogram metrics. The bucket values must be in 'string' format with each bucket value separated by a comma.\nThe expected format of the parameter is as follows: \n\"2,4,6,8\"\n\n        \nnull\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nquantiles\n\n        \nThe user preferred quantile values for summary metrics. The quantile values must be in 'string' format with each quantile value separated by a comma.\nThe expected format of the parameter is as follows: \n\"0.5,0.75,0.95\"\n\n        \nnull\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nquantile.error\n\n        \nThe error tolerance value for calculating quantiles in summary metrics. This must be a positive value though less than 1.\n\n        \n0.001\n\n        \nDOUBLE\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nvalue.attribute\n\n        \nThe name of the attribute in stream definition which specifies the metric value. The defined value attribute must be included inside the stream attributes. The value of the 'value' attribute that is published through events, increase the metric value for the counter and gauge metric types. For histogram and summary metric types, the values are observed.\n\n        \nvalue\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npush.operation\n\n        \nThis parameter defines the mode for pushing metrics to pushGateway The available push operations are 'push' and 'pushadd'. The operations differ according to the existing metrics in pushGateway where 'push' operation replaces the existing metrics and 'pushadd' operation only updates the newly created metrics.\n\n        \npushadd\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ngrouping.key\n\n        \nThis parameter specifies the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics. \nThe expected format of the grouping key is as follows:\n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n\n\n\nSystem Parameters\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Parameters\n\n    \n\n    \n\n        \njobName\n\n        \nThis is the property that specifies the default job name for the metric. The name must be the same job name as defined in the prometheus configuration file.\n\n        \nsiddhiJob\n\n        \nAny string\n\n    \n\n    \n\n        \npublishMode\n\n        \nThe default publish mode for the Prometheus sink for exposing metrics to Prometheus server. The mode can be either 'server' or 'pushgateway'. \n\n        \nserver\n\n        \nserver or pushgateway\n\n    \n\n    \n\n        \nserverURL\n\n        \nThis property configures the url where the http server will be initiated to expose metrics. This url must be previously defined in prometheus configuration file as a target to be identified by Prometheus. By default, the http server will be initiated at 'http://localhost:9080'\n\n        \nhttp://localhost:9080\n\n        \nAny valid URL\n\n    \n\n    \n\n        \npushURL\n\n        \nThis property configures the target url of Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target to be identified by Prometheus.\n\n        \nhttp://localhost:9091\n\n        \nAny valid URL\n\n    \n\n    \n\n        \ngroupingKey\n\n        \nThis property configures the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics under same job. The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" .\n\n        \nnull\n\n        \nAny key value pairs in the supported format\n\n    \n\n\n\n\nExamples\n\n\nEXAMPLE 1\n\n\n@sink(type=\nprometheus\n,job=\nfooOrderCount\n, server.url =\nhttp://localhost:9080\n, publish.mode=\nserver\n, metric.type=\ncounter\n, metric.help= \nNumber of foo orders\n, @map(type=\nkeyvalue\n))\ndefine stream FooCountStream (Name String, quantity int, value int);\n\n\n\n\n\n In the above example, the Prometheus-sink creates a counter metric with the stream name and defined attributes as labels. The metric is exposed through an http server at the target url.\n\n\n\nEXAMPLE 2\n\n\n@sink(type=\nprometheus\n,job=\ninventoryLevel\n, push.url=\nhttp://localhost:9080\n, publish.mode=\npushGateway\n, metric.type=\ngauge\n, metric.help= \nCurrent level of inventory\n, @map(type=\nkeyvalue\n))\ndefine stream InventoryLevelStream (Name String, value int);\n\n\n\n\n\n In the above example, the Prometheus-sink creates a gauge metric with the stream name and defined attributes as labels.The metric is pushed to Prometheus pushGateway at the target url.\n\n\n\nSource\n\n\nprometheus \n(Source)\n\n\nThe source consumes Prometheus metrics which are exported from the specified url as Siddhi events, by making http requests to the url. According to the source configuration, it analyses metrics from the text response and sends them as Siddhi events through key-value mapping.The user can retrieve metrics of types including, counter, gauge, histogram and summary. Since the source retrieves the metrics from a text response of the target, it is advised to use 'string' as the attribute type for the attributes that correspond to Prometheus metric labels. Further, the Prometheus metric value is passed through the event as 'value'. Therefore, it is advisable to have an attribute with the name 'value' in the stream. \nThe supported types for the attribute, 'value' are INT, LONG, FLOAT and DOUBLE.\n\n\n\nSyntax\n\n\n@source(type=\nprometheus\n, target.url=\nSTRING\n, scrape.interval=\nINT\n, scrape.timeout=\nINT\n, scheme=\nSTRING\n, metric.name=\nSTRING\n, metric.type=\nSTRING\n, username=\nSTRING\n, password=\nSTRING\n, client.truststore.file=\nSTRING\n, client.truststore.password=\nSTRING\n, headers=\nSTRING\n, job=\nSTRING\n, instance=\nSTRING\n, grouping.key=\nSTRING\n, @map(...)))\n\n\n\n\n\nQUERY PARAMETERS\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Data Types\n\n        \nOptional\n\n        \nDynamic\n\n    \n\n    \n\n        \ntarget.url\n\n        \nThis property specifies the target url where the Prometheus metrics are exported in text format.\n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nscrape.interval\n\n        \nThis property specifies the time interval in seconds within which the source should make an HTTP request to the  provided target url.\n\n        \n60\n\n        \nINT\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nscrape.timeout\n\n        \nThis property is the time duration in seconds for a scrape request to get timed-out if the server at the url does not respond.\n\n        \n10\n\n        \nINT\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nscheme\n\n        \nThis property specifies the scheme of the target URL.\nThe supported schemes are 'HTTP' and 'HTTPS'.\n\n        \nHTTP\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.name\n\n        \nThis property specifies the name of the metrics that are to be fetched. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]* .\n\n        \nStream name\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.type\n\n        \nThis property specifies the type of the Prometheus metric that is required to be fetched. \nThe supported metric types are 'counter', 'gauge',\" 'histogram' and 'summary'. \n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nusername\n\n        \nThis property specifies the username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npassword\n\n        \nThis property specifies the password that has to be added in the authorization header of the request, if the basic authentication is enabled at the target. It is required to specify both the username and password to enable basic authentication. If one of the parameter is not given by user, then an error is logged in the console.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nclient.truststore.file\n\n        \nThe file path to the location of the truststore to which the client needs to send https requests through 'https' protocol.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nclient.truststore.password\n\n        \n The password for client-truststore to send https requests. A custom password can be specified if required. \n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nheaders\n\n        \nHeaders that should be included as HTTP request headers in the request. \nThe format of the supported input is as follows, \n\"'header1:value1','header2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \njob\n\n        \n This property defines the job name of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ninstance\n\n        \nThis property defines the instance of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ngrouping.key\n\n        \nThis parameter specifies the grouping key of the required metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics.\nThe expected format of the grouping key is as follows: \n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n\n\n\nSystem Parameters\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Parameters\n\n    \n\n    \n\n        \nscrapeInterval\n\n        \nThe default time interval in seconds for the Prometheus source to make HTTP requests to the target URL.\n\n        \n60\n\n        \nAny integer value\n\n    \n\n    \n\n        \nscrapeTimeout\n\n        \nThis default time duration (in seconds) for an HTTP request to time-out if the server at the URL does not respond. \n\n        \n10\n\n        \nAny integer value\n\n    \n\n    \n\n        \nscheme\n\n        \nThe scheme of the target for Prometheus source to make HTTP requests. The supported schemes are HTTP and HTTPS.\n\n        \nHTTP\n\n        \nHTTP or HTTPS\n\n    \n\n    \n\n        \nusername\n\n        \nThe username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nAny string\n\n    \n\n    \n\n        \npassword\n\n        \nThe password that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nAny string\n\n    \n\n    \n\n        \ntrustStoreFile\n\n        \nThe default file path to the location of truststore that the client needs to send for HTTPS requests through 'HTTPS' protocol.\n\n        \n${carbon.home}/resources/security/client-truststore.jks\n\n        \nAny valid path for the truststore file\n\n    \n\n    \n\n        \ntrustStorePassword\n\n        \nThe default password for the client-truststore to send HTTPS requests.\n\n        \nwso2carbon\n\n        \nAny string\n\n    \n\n    \n\n        \nheaders\n\n        \nThe headers that should be included as HTTP request headers in the scrape request. \nThe format of the supported input is as follows, \n\"'header1:value1','header2:value2'\"\n\n        \n\n        \nAny valid http headers\n\n    \n\n    \n\n        \njob\n\n        \n The default job name of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nAny valid job name\n\n    \n\n    \n\n        \ninstance\n\n        \nThe default instance of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nAny valid instance name\n\n    \n\n    \n\n        \ngroupingKey\n\n        \nThe default grouping key of the required Prometheus metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics. \nThe expected format of the grouping key is as follows: \n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nAny valid grouping key pairs\n\n    \n\n\n\n\nExamples\n\n\nEXAMPLE 1\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \ncounter\n, metric.name= \nsweet_production_counter\n, @map(type= \nkeyvalue\n))\ndefine stream FooStream1(metric_name string, metric_type string, help string, subtype string, name string, quantity string, value double);\n\n\n\n\n\nIn this example, the prometheus source makes an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus counter metrics with the name, 'sweet_production_counter' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps will have keys and values as follows: \nmetric_name  -\n sweet_production_counter\nmetric_type  -\n counter\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n null\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nvalue -\n \nvalue_of_metric\n\n\n\nEXAMPLE 2\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \nsummary\n, metric.name= \nsweet_production_summary\n, @map(type= \nkeyvalue\n))\n define stream FooStream2(metric_name string, metric_type string, help string, subtype string, name string, quantity string, quantile string, value double);\n\n\n\n\n\nIn this example, the prometheus source makes an http request to the 'target.url' and analyses the response. From the analysed response, the source retrieves the Prometheus summary metrics with the name, 'sweet_production_summary' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps have keys and values as follows: \nmetric_name  -\n sweet_production_summary\nmetric_type  -\n summary\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n \n'sum'/'count'/'null'\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nquantile  -\n \nvalue of the quantile\nvalue -\n \nvalue_of_metric\n\n\n\nEXAMPLE 3\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \nhistogram\n, metric.name= \nsweet_production_histogram\n, @map(type= \nkeyvalue\n))\ndefine stream FooStream3(metric_name string, metric_type string, help string, subtype string, name string, quantity string, le string, value double);\n\n\n\n\n\nIn this example, the prometheus source will make an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus histogram metrics with name 'sweet_production_histogram' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps will have keys and values as follows, \nmetric_name  -\n sweet_production_histogram\nmetric_type  -\n histogram\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n \n'sum'/'count'/'bucket'\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nle  -\n \nvalue of the bucket\nvalue -\n \nvalue_of_metric", 
            "title": "1.0.0"
        }, 
        {
            "location": "/api/1.0.0/#api-docs-v100", 
            "text": "", 
            "title": "API Docs - v1.0.0"
        }, 
        {
            "location": "/api/1.0.0/#sink", 
            "text": "", 
            "title": "Sink"
        }, 
        {
            "location": "/api/1.0.0/#prometheus-sink", 
            "text": "The sink publishes events processed by WSO2 SP into Prometheus metrics and exposes them to Prometheus server at the provided url. The created metrics can be published to Prometheus through 'server' or 'pushGateway' publishing modes depending on the preference of the user. The server mode exposes the metrics through an http server at the provided url and the pushGateway mode pushes the metrics to pushGateway which must be running at the provided url. The metric types that are supported by Prometheus sink are counter, gauge, histogram and summary. The values and labels of the Prometheus metrics can be updated through the events.   Syntax  @sink(type= prometheus , job= STRING , publish.mode= STRING , push.url= STRING , server.url= STRING , metric.type= STRING , metric.help= STRING , metric.name= STRING , buckets= STRING , quantiles= STRING , quantile.error= DOUBLE , value.attribute= STRING , push.operation= STRING , grouping.key= STRING , @map(...)))  QUERY PARAMETERS  \n     \n         Name \n         Description \n         Default Value \n         Possible Data Types \n         Optional \n         Dynamic \n     \n     \n         job \n         This parameter specifies the job name of the metric. The name must be the same job name as defined in the prometheus configuration file. \n         siddhiJob \n         STRING \n         Yes \n         No \n     \n     \n         publish.mode \n         This parameter specifies the mode of exposing metrics to Prometheus server.The possible publishing modes are 'server' and 'pushgateway'. \n         server \n         STRING \n         Yes \n         No \n     \n     \n         push.url \n         This parameter specifies the target url of the Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target. \n         http://localhost:9091 \n         STRING \n         Yes \n         No \n     \n     \n         server.url \n         This parameter specifies the url where the http server is initiated to expose metrics for 'server' publish mode. This url must be previously defined in prometheus configuration file as a target. \n         http://localhost:9080 \n         STRING \n         Yes \n         No \n     \n     \n         metric.type \n         The type of Prometheus metric that has to be created at the sink. The supported metric types are 'counter', 'gauge', 'histogram' and 'summary'.  \n         \n         STRING \n         No \n         No \n     \n     \n         metric.help \n         A brief description of the metric and its purpose. \n         \n         STRING \n         Yes \n         No \n     \n     \n         metric.name \n         This parameter specifies the user preferred name for the metric. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]*.  \n         \n         STRING \n         Yes \n         No \n     \n     \n         buckets \n         The bucket values preferred by the user for histogram metrics. The bucket values must be in 'string' format with each bucket value separated by a comma. The expected format of the parameter is as follows:  \"2,4,6,8\" \n         null \n         STRING \n         Yes \n         No \n     \n     \n         quantiles \n         The user preferred quantile values for summary metrics. The quantile values must be in 'string' format with each quantile value separated by a comma. The expected format of the parameter is as follows:  \"0.5,0.75,0.95\" \n         null \n         STRING \n         Yes \n         No \n     \n     \n         quantile.error \n         The error tolerance value for calculating quantiles in summary metrics. This must be a positive value though less than 1. \n         0.001 \n         DOUBLE \n         Yes \n         No \n     \n     \n         value.attribute \n         The name of the attribute in stream definition which specifies the metric value. The defined value attribute must be included inside the stream attributes. The value of the 'value' attribute that is published through events, increase the metric value for the counter and gauge metric types. For histogram and summary metric types, the values are observed. \n         value \n         STRING \n         Yes \n         No \n     \n     \n         push.operation \n         This parameter defines the mode for pushing metrics to pushGateway The available push operations are 'push' and 'pushadd'. The operations differ according to the existing metrics in pushGateway where 'push' operation replaces the existing metrics and 'pushadd' operation only updates the newly created metrics. \n         pushadd \n         STRING \n         Yes \n         No \n     \n     \n         grouping.key \n         This parameter specifies the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics.  The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" \n         \n         STRING \n         Yes \n         No \n       System Parameters  \n     \n         Name \n         Description \n         Default Value \n         Possible Parameters \n     \n     \n         jobName \n         This is the property that specifies the default job name for the metric. The name must be the same job name as defined in the prometheus configuration file. \n         siddhiJob \n         Any string \n     \n     \n         publishMode \n         The default publish mode for the Prometheus sink for exposing metrics to Prometheus server. The mode can be either 'server' or 'pushgateway'.  \n         server \n         server or pushgateway \n     \n     \n         serverURL \n         This property configures the url where the http server will be initiated to expose metrics. This url must be previously defined in prometheus configuration file as a target to be identified by Prometheus. By default, the http server will be initiated at 'http://localhost:9080' \n         http://localhost:9080 \n         Any valid URL \n     \n     \n         pushURL \n         This property configures the target url of Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target to be identified by Prometheus. \n         http://localhost:9091 \n         Any valid URL \n     \n     \n         groupingKey \n         This property configures the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics under same job. The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" . \n         null \n         Any key value pairs in the supported format \n       Examples  EXAMPLE 1  @sink(type= prometheus ,job= fooOrderCount , server.url = http://localhost:9080 , publish.mode= server , metric.type= counter , metric.help=  Number of foo orders , @map(type= keyvalue ))\ndefine stream FooCountStream (Name String, quantity int, value int);   In the above example, the Prometheus-sink creates a counter metric with the stream name and defined attributes as labels. The metric is exposed through an http server at the target url.  EXAMPLE 2  @sink(type= prometheus ,job= inventoryLevel , push.url= http://localhost:9080 , publish.mode= pushGateway , metric.type= gauge , metric.help=  Current level of inventory , @map(type= keyvalue ))\ndefine stream InventoryLevelStream (Name String, value int);   In the above example, the Prometheus-sink creates a gauge metric with the stream name and defined attributes as labels.The metric is pushed to Prometheus pushGateway at the target url.", 
            "title": "prometheus (Sink)"
        }, 
        {
            "location": "/api/1.0.0/#source", 
            "text": "", 
            "title": "Source"
        }, 
        {
            "location": "/api/1.0.0/#prometheus-source", 
            "text": "The source consumes Prometheus metrics which are exported from the specified url as Siddhi events, by making http requests to the url. According to the source configuration, it analyses metrics from the text response and sends them as Siddhi events through key-value mapping.The user can retrieve metrics of types including, counter, gauge, histogram and summary. Since the source retrieves the metrics from a text response of the target, it is advised to use 'string' as the attribute type for the attributes that correspond to Prometheus metric labels. Further, the Prometheus metric value is passed through the event as 'value'. Therefore, it is advisable to have an attribute with the name 'value' in the stream.  The supported types for the attribute, 'value' are INT, LONG, FLOAT and DOUBLE.  Syntax  @source(type= prometheus , target.url= STRING , scrape.interval= INT , scrape.timeout= INT , scheme= STRING , metric.name= STRING , metric.type= STRING , username= STRING , password= STRING , client.truststore.file= STRING , client.truststore.password= STRING , headers= STRING , job= STRING , instance= STRING , grouping.key= STRING , @map(...)))  QUERY PARAMETERS  \n     \n         Name \n         Description \n         Default Value \n         Possible Data Types \n         Optional \n         Dynamic \n     \n     \n         target.url \n         This property specifies the target url where the Prometheus metrics are exported in text format. \n         \n         STRING \n         No \n         No \n     \n     \n         scrape.interval \n         This property specifies the time interval in seconds within which the source should make an HTTP request to the  provided target url. \n         60 \n         INT \n         Yes \n         No \n     \n     \n         scrape.timeout \n         This property is the time duration in seconds for a scrape request to get timed-out if the server at the url does not respond. \n         10 \n         INT \n         Yes \n         No \n     \n     \n         scheme \n         This property specifies the scheme of the target URL. The supported schemes are 'HTTP' and 'HTTPS'. \n         HTTP \n         STRING \n         Yes \n         No \n     \n     \n         metric.name \n         This property specifies the name of the metrics that are to be fetched. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]* . \n         Stream name \n         STRING \n         Yes \n         No \n     \n     \n         metric.type \n         This property specifies the type of the Prometheus metric that is required to be fetched.  The supported metric types are 'counter', 'gauge',\" 'histogram' and 'summary'.  \n         \n         STRING \n         No \n         No \n     \n     \n         username \n         This property specifies the username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         STRING \n         Yes \n         No \n     \n     \n         password \n         This property specifies the password that has to be added in the authorization header of the request, if the basic authentication is enabled at the target. It is required to specify both the username and password to enable basic authentication. If one of the parameter is not given by user, then an error is logged in the console. \n         \n         STRING \n         Yes \n         No \n     \n     \n         client.truststore.file \n         The file path to the location of the truststore to which the client needs to send https requests through 'https' protocol. \n         \n         STRING \n         Yes \n         No \n     \n     \n         client.truststore.password \n          The password for client-truststore to send https requests. A custom password can be specified if required.  \n         \n         STRING \n         Yes \n         No \n     \n     \n         headers \n         Headers that should be included as HTTP request headers in the request.  The format of the supported input is as follows,  \"'header1:value1','header2:value2'\" \n         \n         STRING \n         Yes \n         No \n     \n     \n         job \n          This property defines the job name of the exported Prometheus metrics that has to be fetched. \n         \n         STRING \n         Yes \n         No \n     \n     \n         instance \n         This property defines the instance of the exported Prometheus metrics that has to be fetched. \n         \n         STRING \n         Yes \n         No \n     \n     \n         grouping.key \n         This parameter specifies the grouping key of the required metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics. The expected format of the grouping key is as follows:  \"'key1:value1','key2:value2'\" \n         \n         STRING \n         Yes \n         No \n       System Parameters  \n     \n         Name \n         Description \n         Default Value \n         Possible Parameters \n     \n     \n         scrapeInterval \n         The default time interval in seconds for the Prometheus source to make HTTP requests to the target URL. \n         60 \n         Any integer value \n     \n     \n         scrapeTimeout \n         This default time duration (in seconds) for an HTTP request to time-out if the server at the URL does not respond.  \n         10 \n         Any integer value \n     \n     \n         scheme \n         The scheme of the target for Prometheus source to make HTTP requests. The supported schemes are HTTP and HTTPS. \n         HTTP \n         HTTP or HTTPS \n     \n     \n         username \n         The username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         Any string \n     \n     \n         password \n         The password that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         Any string \n     \n     \n         trustStoreFile \n         The default file path to the location of truststore that the client needs to send for HTTPS requests through 'HTTPS' protocol. \n         ${carbon.home}/resources/security/client-truststore.jks \n         Any valid path for the truststore file \n     \n     \n         trustStorePassword \n         The default password for the client-truststore to send HTTPS requests. \n         wso2carbon \n         Any string \n     \n     \n         headers \n         The headers that should be included as HTTP request headers in the scrape request.  The format of the supported input is as follows,  \"'header1:value1','header2:value2'\" \n         \n         Any valid http headers \n     \n     \n         job \n          The default job name of the exported Prometheus metrics that has to be fetched. \n         \n         Any valid job name \n     \n     \n         instance \n         The default instance of the exported Prometheus metrics that has to be fetched. \n         \n         Any valid instance name \n     \n     \n         groupingKey \n         The default grouping key of the required Prometheus metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics.  The expected format of the grouping key is as follows:  \"'key1:value1','key2:value2'\" \n         \n         Any valid grouping key pairs \n       Examples  EXAMPLE 1  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  counter , metric.name=  sweet_production_counter , @map(type=  keyvalue ))\ndefine stream FooStream1(metric_name string, metric_type string, help string, subtype string, name string, quantity string, value double);  In this example, the prometheus source makes an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus counter metrics with the name, 'sweet_production_counter' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps will have keys and values as follows:  metric_name  -  sweet_production_counter metric_type  -  counter help  -   help_string_of_metric subtype  -  null name -   value_of_label_name quantity -   value_of_label_quantity value -   value_of_metric  EXAMPLE 2  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  summary , metric.name=  sweet_production_summary , @map(type=  keyvalue ))\n define stream FooStream2(metric_name string, metric_type string, help string, subtype string, name string, quantity string, quantile string, value double);  In this example, the prometheus source makes an http request to the 'target.url' and analyses the response. From the analysed response, the source retrieves the Prometheus summary metrics with the name, 'sweet_production_summary' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps have keys and values as follows:  metric_name  -  sweet_production_summary metric_type  -  summary help  -   help_string_of_metric subtype  -   'sum'/'count'/'null' name -   value_of_label_name quantity -   value_of_label_quantity quantile  -   value of the quantile value -   value_of_metric  EXAMPLE 3  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  histogram , metric.name=  sweet_production_histogram , @map(type=  keyvalue ))\ndefine stream FooStream3(metric_name string, metric_type string, help string, subtype string, name string, quantity string, le string, value double);  In this example, the prometheus source will make an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus histogram metrics with name 'sweet_production_histogram' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps will have keys and values as follows,  metric_name  -  sweet_production_histogram metric_type  -  histogram help  -   help_string_of_metric subtype  -   'sum'/'count'/'bucket' name -   value_of_label_name quantity -   value_of_label_quantity le  -   value of the bucket value -   value_of_metric", 
            "title": "prometheus (Source)"
        }, 
        {
            "location": "/api/latest/", 
            "text": "API Docs - v1.0.1\n\n\nSink\n\n\nprometheus \n(Sink)\n\n\nThe sink publishes events processed by Siddhi into Prometheus metrics and exposes them to Prometheus server at the provided url. The created metrics can be published to Prometheus through 'server' or 'pushGateway' publishing modes depending on the preference of the user. The server mode exposes the metrics through an http server at the provided url and the pushGateway mode pushes the metrics to pushGateway which must be running at the provided url.\nThe metric types that are supported by Prometheus sink are counter, gauge, histogram and summary. The values and labels of the Prometheus metrics can be updated through the events. \n\n\n\nSyntax\n\n\n@sink(type=\nprometheus\n, job=\nSTRING\n, publish.mode=\nSTRING\n, push.url=\nSTRING\n, server.url=\nSTRING\n, metric.type=\nSTRING\n, metric.help=\nSTRING\n, metric.name=\nSTRING\n, buckets=\nSTRING\n, quantiles=\nSTRING\n, quantile.error=\nDOUBLE\n, value.attribute=\nSTRING\n, push.operation=\nSTRING\n, grouping.key=\nSTRING\n, @map(...)))\n\n\n\n\n\nQUERY PARAMETERS\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Data Types\n\n        \nOptional\n\n        \nDynamic\n\n    \n\n    \n\n        \njob\n\n        \nThis parameter specifies the job name of the metric. The name must be the same job name as defined in the prometheus configuration file.\n\n        \nsiddhiJob\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npublish.mode\n\n        \nThis parameter specifies the mode of exposing metrics to Prometheus server.The possible publishing modes are 'server' and 'pushgateway'.\n\n        \nserver\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npush.url\n\n        \nThis parameter specifies the target url of the Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target.\n\n        \nhttp://localhost:9091\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nserver.url\n\n        \nThis parameter specifies the url where the http server is initiated to expose metrics for 'server' publish mode. This url must be previously defined in prometheus configuration file as a target.\n\n        \nhttp://localhost:9080\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.type\n\n        \nThe type of Prometheus metric that has to be created at the sink.\nThe supported metric types are 'counter', 'gauge', 'histogram' and 'summary'. \n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.help\n\n        \nA brief description of the metric and its purpose.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.name\n\n        \nThis parameter specifies the user preferred name for the metric. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]*. \n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nbuckets\n\n        \nThe bucket values preferred by the user for histogram metrics. The bucket values must be in 'string' format with each bucket value separated by a comma.\nThe expected format of the parameter is as follows: \n\"2,4,6,8\"\n\n        \nnull\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nquantiles\n\n        \nThe user preferred quantile values for summary metrics. The quantile values must be in 'string' format with each quantile value separated by a comma.\nThe expected format of the parameter is as follows: \n\"0.5,0.75,0.95\"\n\n        \nnull\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nquantile.error\n\n        \nThe error tolerance value for calculating quantiles in summary metrics. This must be a positive value though less than 1.\n\n        \n0.001\n\n        \nDOUBLE\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nvalue.attribute\n\n        \nThe name of the attribute in stream definition which specifies the metric value. The defined value attribute must be included inside the stream attributes. The value of the 'value' attribute that is published through events, increase the metric value for the counter and gauge metric types. For histogram and summary metric types, the values are observed.\n\n        \nvalue\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npush.operation\n\n        \nThis parameter defines the mode for pushing metrics to pushGateway The available push operations are 'push' and 'pushadd'. The operations differ according to the existing metrics in pushGateway where 'push' operation replaces the existing metrics and 'pushadd' operation only updates the newly created metrics.\n\n        \npushadd\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ngrouping.key\n\n        \nThis parameter specifies the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics. \nThe expected format of the grouping key is as follows:\n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n\n\n\nSystem Parameters\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Parameters\n\n    \n\n    \n\n        \njobName\n\n        \nThis is the property that specifies the default job name for the metric. The name must be the same job name as defined in the prometheus configuration file.\n\n        \nsiddhiJob\n\n        \nAny string\n\n    \n\n    \n\n        \npublishMode\n\n        \nThe default publish mode for the Prometheus sink for exposing metrics to Prometheus server. The mode can be either 'server' or 'pushgateway'. \n\n        \nserver\n\n        \nserver or pushgateway\n\n    \n\n    \n\n        \nserverURL\n\n        \nThis property configures the url where the http server will be initiated to expose metrics. This url must be previously defined in prometheus configuration file as a target to be identified by Prometheus. By default, the http server will be initiated at 'http://localhost:9080'\n\n        \nhttp://localhost:9080\n\n        \nAny valid URL\n\n    \n\n    \n\n        \npushURL\n\n        \nThis property configures the target url of Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target to be identified by Prometheus.\n\n        \nhttp://localhost:9091\n\n        \nAny valid URL\n\n    \n\n    \n\n        \ngroupingKey\n\n        \nThis property configures the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics under same job. The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" .\n\n        \nnull\n\n        \nAny key value pairs in the supported format\n\n    \n\n\n\n\nExamples\n\n\nEXAMPLE 1\n\n\n@sink(type=\nprometheus\n,job=\nfooOrderCount\n, server.url =\nhttp://localhost:9080\n, publish.mode=\nserver\n, metric.type=\ncounter\n, metric.help= \nNumber of foo orders\n, @map(type=\nkeyvalue\n))\ndefine stream FooCountStream (Name String, quantity int, value int);\n\n\n\n\n\n In the above example, the Prometheus-sink creates a counter metric with the stream name and defined attributes as labels. The metric is exposed through an http server at the target url.\n\n\n\nEXAMPLE 2\n\n\n@sink(type=\nprometheus\n,job=\ninventoryLevel\n, push.url=\nhttp://localhost:9080\n, publish.mode=\npushGateway\n, metric.type=\ngauge\n, metric.help= \nCurrent level of inventory\n, @map(type=\nkeyvalue\n))\ndefine stream InventoryLevelStream (Name String, value int);\n\n\n\n\n\n In the above example, the Prometheus-sink creates a gauge metric with the stream name and defined attributes as labels.The metric is pushed to Prometheus pushGateway at the target url.\n\n\n\nSource\n\n\nprometheus \n(Source)\n\n\nThe source consumes Prometheus metrics which are exported from the specified url as Siddhi events, by making http requests to the url. According to the source configuration, it analyses metrics from the text response and sends them as Siddhi events through key-value mapping.The user can retrieve metrics of types including, counter, gauge, histogram and summary. Since the source retrieves the metrics from a text response of the target, it is advised to use 'string' as the attribute type for the attributes that correspond to Prometheus metric labels. Further, the Prometheus metric value is passed through the event as 'value'. Therefore, it is advisable to have an attribute with the name 'value' in the stream. \nThe supported types for the attribute, 'value' are INT, LONG, FLOAT and DOUBLE.\n\n\n\nSyntax\n\n\n@source(type=\nprometheus\n, target.url=\nSTRING\n, scrape.interval=\nINT\n, scrape.timeout=\nINT\n, scheme=\nSTRING\n, metric.name=\nSTRING\n, metric.type=\nSTRING\n, username=\nSTRING\n, password=\nSTRING\n, client.truststore.file=\nSTRING\n, client.truststore.password=\nSTRING\n, headers=\nSTRING\n, job=\nSTRING\n, instance=\nSTRING\n, grouping.key=\nSTRING\n, @map(...)))\n\n\n\n\n\nQUERY PARAMETERS\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Data Types\n\n        \nOptional\n\n        \nDynamic\n\n    \n\n    \n\n        \ntarget.url\n\n        \nThis property specifies the target url where the Prometheus metrics are exported in text format.\n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nscrape.interval\n\n        \nThis property specifies the time interval in seconds within which the source should make an HTTP request to the  provided target url.\n\n        \n60\n\n        \nINT\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nscrape.timeout\n\n        \nThis property is the time duration in seconds for a scrape request to get timed-out if the server at the url does not respond.\n\n        \n10\n\n        \nINT\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nscheme\n\n        \nThis property specifies the scheme of the target URL.\nThe supported schemes are 'HTTP' and 'HTTPS'.\n\n        \nHTTP\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.name\n\n        \nThis property specifies the name of the metrics that are to be fetched. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]* .\n\n        \nStream name\n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nmetric.type\n\n        \nThis property specifies the type of the Prometheus metric that is required to be fetched. \nThe supported metric types are 'counter', 'gauge',\" 'histogram' and 'summary'. \n\n        \n\n        \nSTRING\n\n        \nNo\n\n        \nNo\n\n    \n\n    \n\n        \nusername\n\n        \nThis property specifies the username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \npassword\n\n        \nThis property specifies the password that has to be added in the authorization header of the request, if the basic authentication is enabled at the target. It is required to specify both the username and password to enable basic authentication. If one of the parameter is not given by user, then an error is logged in the console.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nclient.truststore.file\n\n        \nThe file path to the location of the truststore to which the client needs to send https requests through 'https' protocol.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nclient.truststore.password\n\n        \n The password for client-truststore to send https requests. A custom password can be specified if required. \n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \nheaders\n\n        \nHeaders that should be included as HTTP request headers in the request. \nThe format of the supported input is as follows, \n\"'header1:value1','header2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \njob\n\n        \n This property defines the job name of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ninstance\n\n        \nThis property defines the instance of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n    \n\n        \ngrouping.key\n\n        \nThis parameter specifies the grouping key of the required metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics.\nThe expected format of the grouping key is as follows: \n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nSTRING\n\n        \nYes\n\n        \nNo\n\n    \n\n\n\n\nSystem Parameters\n\n\n\n    \n\n        \nName\n\n        \nDescription\n\n        \nDefault Value\n\n        \nPossible Parameters\n\n    \n\n    \n\n        \nscrapeInterval\n\n        \nThe default time interval in seconds for the Prometheus source to make HTTP requests to the target URL.\n\n        \n60\n\n        \nAny integer value\n\n    \n\n    \n\n        \nscrapeTimeout\n\n        \nThis default time duration (in seconds) for an HTTP request to time-out if the server at the URL does not respond. \n\n        \n10\n\n        \nAny integer value\n\n    \n\n    \n\n        \nscheme\n\n        \nThe scheme of the target for Prometheus source to make HTTP requests. The supported schemes are HTTP and HTTPS.\n\n        \nHTTP\n\n        \nHTTP or HTTPS\n\n    \n\n    \n\n        \nusername\n\n        \nThe username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nAny string\n\n    \n\n    \n\n        \npassword\n\n        \nThe password that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console.\n\n        \n\n        \nAny string\n\n    \n\n    \n\n        \ntrustStoreFile\n\n        \nThe default file path to the location of truststore that the client needs to send for HTTPS requests through 'HTTPS' protocol.\n\n        \n${carbon.home}/resources/security/client-truststore.jks\n\n        \nAny valid path for the truststore file\n\n    \n\n    \n\n        \ntrustStorePassword\n\n        \nThe default password for the client-truststore to send HTTPS requests.\n\n        \nwso2carbon\n\n        \nAny string\n\n    \n\n    \n\n        \nheaders\n\n        \nThe headers that should be included as HTTP request headers in the scrape request. \nThe format of the supported input is as follows, \n\"'header1:value1','header2:value2'\"\n\n        \n\n        \nAny valid http headers\n\n    \n\n    \n\n        \njob\n\n        \n The default job name of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nAny valid job name\n\n    \n\n    \n\n        \ninstance\n\n        \nThe default instance of the exported Prometheus metrics that has to be fetched.\n\n        \n\n        \nAny valid instance name\n\n    \n\n    \n\n        \ngroupingKey\n\n        \nThe default grouping key of the required Prometheus metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics. \nThe expected format of the grouping key is as follows: \n\"'key1:value1','key2:value2'\"\n\n        \n\n        \nAny valid grouping key pairs\n\n    \n\n\n\n\nExamples\n\n\nEXAMPLE 1\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \ncounter\n, metric.name= \nsweet_production_counter\n, @map(type= \nkeyvalue\n))\ndefine stream FooStream1(metric_name string, metric_type string, help string, subtype string, name string, quantity string, value double);\n\n\n\n\n\nIn this example, the prometheus source makes an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus counter metrics with the name, 'sweet_production_counter' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps will have keys and values as follows: \nmetric_name  -\n sweet_production_counter\nmetric_type  -\n counter\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n null\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nvalue -\n \nvalue_of_metric\n\n\n\nEXAMPLE 2\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \nsummary\n, metric.name= \nsweet_production_summary\n, @map(type= \nkeyvalue\n))\n define stream FooStream2(metric_name string, metric_type string, help string, subtype string, name string, quantity string, quantile string, value double);\n\n\n\n\n\nIn this example, the prometheus source makes an http request to the 'target.url' and analyses the response. From the analysed response, the source retrieves the Prometheus summary metrics with the name, 'sweet_production_summary' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps have keys and values as follows: \nmetric_name  -\n sweet_production_summary\nmetric_type  -\n summary\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n \n'sum'/'count'/'null'\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nquantile  -\n \nvalue of the quantile\nvalue -\n \nvalue_of_metric\n\n\n\nEXAMPLE 3\n\n\n@source(type= \nprometheus\n, target.url= \nhttp://localhost:9080/metrics\n, metric.type= \nhistogram\n, metric.name= \nsweet_production_histogram\n, @map(type= \nkeyvalue\n))\ndefine stream FooStream3(metric_name string, metric_type string, help string, subtype string, name string, quantity string, le string, value double);\n\n\n\n\n\nIn this example, the prometheus source will make an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus histogram metrics with name 'sweet_production_histogram' and converts the filtered metrics into Siddhi events using the key-value mapper.\nThe generated maps will have keys and values as follows, \nmetric_name  -\n sweet_production_histogram\nmetric_type  -\n histogram\nhelp  -\n \nhelp_string_of_metric\nsubtype  -\n \n'sum'/'count'/'bucket'\nname -\n \nvalue_of_label_name\nquantity -\n \nvalue_of_label_quantity\nle  -\n \nvalue of the bucket\nvalue -\n \nvalue_of_metric", 
            "title": "latest"
        }, 
        {
            "location": "/api/latest/#api-docs-v101", 
            "text": "", 
            "title": "API Docs - v1.0.1"
        }, 
        {
            "location": "/api/latest/#sink", 
            "text": "", 
            "title": "Sink"
        }, 
        {
            "location": "/api/latest/#prometheus-sink", 
            "text": "The sink publishes events processed by Siddhi into Prometheus metrics and exposes them to Prometheus server at the provided url. The created metrics can be published to Prometheus through 'server' or 'pushGateway' publishing modes depending on the preference of the user. The server mode exposes the metrics through an http server at the provided url and the pushGateway mode pushes the metrics to pushGateway which must be running at the provided url. The metric types that are supported by Prometheus sink are counter, gauge, histogram and summary. The values and labels of the Prometheus metrics can be updated through the events.   Syntax  @sink(type= prometheus , job= STRING , publish.mode= STRING , push.url= STRING , server.url= STRING , metric.type= STRING , metric.help= STRING , metric.name= STRING , buckets= STRING , quantiles= STRING , quantile.error= DOUBLE , value.attribute= STRING , push.operation= STRING , grouping.key= STRING , @map(...)))  QUERY PARAMETERS  \n     \n         Name \n         Description \n         Default Value \n         Possible Data Types \n         Optional \n         Dynamic \n     \n     \n         job \n         This parameter specifies the job name of the metric. The name must be the same job name as defined in the prometheus configuration file. \n         siddhiJob \n         STRING \n         Yes \n         No \n     \n     \n         publish.mode \n         This parameter specifies the mode of exposing metrics to Prometheus server.The possible publishing modes are 'server' and 'pushgateway'. \n         server \n         STRING \n         Yes \n         No \n     \n     \n         push.url \n         This parameter specifies the target url of the Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target. \n         http://localhost:9091 \n         STRING \n         Yes \n         No \n     \n     \n         server.url \n         This parameter specifies the url where the http server is initiated to expose metrics for 'server' publish mode. This url must be previously defined in prometheus configuration file as a target. \n         http://localhost:9080 \n         STRING \n         Yes \n         No \n     \n     \n         metric.type \n         The type of Prometheus metric that has to be created at the sink. The supported metric types are 'counter', 'gauge', 'histogram' and 'summary'.  \n         \n         STRING \n         No \n         No \n     \n     \n         metric.help \n         A brief description of the metric and its purpose. \n         \n         STRING \n         Yes \n         No \n     \n     \n         metric.name \n         This parameter specifies the user preferred name for the metric. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]*.  \n         \n         STRING \n         Yes \n         No \n     \n     \n         buckets \n         The bucket values preferred by the user for histogram metrics. The bucket values must be in 'string' format with each bucket value separated by a comma. The expected format of the parameter is as follows:  \"2,4,6,8\" \n         null \n         STRING \n         Yes \n         No \n     \n     \n         quantiles \n         The user preferred quantile values for summary metrics. The quantile values must be in 'string' format with each quantile value separated by a comma. The expected format of the parameter is as follows:  \"0.5,0.75,0.95\" \n         null \n         STRING \n         Yes \n         No \n     \n     \n         quantile.error \n         The error tolerance value for calculating quantiles in summary metrics. This must be a positive value though less than 1. \n         0.001 \n         DOUBLE \n         Yes \n         No \n     \n     \n         value.attribute \n         The name of the attribute in stream definition which specifies the metric value. The defined value attribute must be included inside the stream attributes. The value of the 'value' attribute that is published through events, increase the metric value for the counter and gauge metric types. For histogram and summary metric types, the values are observed. \n         value \n         STRING \n         Yes \n         No \n     \n     \n         push.operation \n         This parameter defines the mode for pushing metrics to pushGateway The available push operations are 'push' and 'pushadd'. The operations differ according to the existing metrics in pushGateway where 'push' operation replaces the existing metrics and 'pushadd' operation only updates the newly created metrics. \n         pushadd \n         STRING \n         Yes \n         No \n     \n     \n         grouping.key \n         This parameter specifies the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics.  The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" \n         \n         STRING \n         Yes \n         No \n       System Parameters  \n     \n         Name \n         Description \n         Default Value \n         Possible Parameters \n     \n     \n         jobName \n         This is the property that specifies the default job name for the metric. The name must be the same job name as defined in the prometheus configuration file. \n         siddhiJob \n         Any string \n     \n     \n         publishMode \n         The default publish mode for the Prometheus sink for exposing metrics to Prometheus server. The mode can be either 'server' or 'pushgateway'.  \n         server \n         server or pushgateway \n     \n     \n         serverURL \n         This property configures the url where the http server will be initiated to expose metrics. This url must be previously defined in prometheus configuration file as a target to be identified by Prometheus. By default, the http server will be initiated at 'http://localhost:9080' \n         http://localhost:9080 \n         Any valid URL \n     \n     \n         pushURL \n         This property configures the target url of Prometheus pushGateway where the pushGateway must be listening. This url should be previously defined in prometheus configuration file as a target to be identified by Prometheus. \n         http://localhost:9091 \n         Any valid URL \n     \n     \n         groupingKey \n         This property configures the grouping key of created metrics in key-value pairs. Grouping key is used only in pushGateway mode in order to distinguish the metrics from already existing metrics under same job. The expected format of the grouping key is as follows: \"'key1:value1','key2:value2'\" . \n         null \n         Any key value pairs in the supported format \n       Examples  EXAMPLE 1  @sink(type= prometheus ,job= fooOrderCount , server.url = http://localhost:9080 , publish.mode= server , metric.type= counter , metric.help=  Number of foo orders , @map(type= keyvalue ))\ndefine stream FooCountStream (Name String, quantity int, value int);   In the above example, the Prometheus-sink creates a counter metric with the stream name and defined attributes as labels. The metric is exposed through an http server at the target url.  EXAMPLE 2  @sink(type= prometheus ,job= inventoryLevel , push.url= http://localhost:9080 , publish.mode= pushGateway , metric.type= gauge , metric.help=  Current level of inventory , @map(type= keyvalue ))\ndefine stream InventoryLevelStream (Name String, value int);   In the above example, the Prometheus-sink creates a gauge metric with the stream name and defined attributes as labels.The metric is pushed to Prometheus pushGateway at the target url.", 
            "title": "prometheus (Sink)"
        }, 
        {
            "location": "/api/latest/#source", 
            "text": "", 
            "title": "Source"
        }, 
        {
            "location": "/api/latest/#prometheus-source", 
            "text": "The source consumes Prometheus metrics which are exported from the specified url as Siddhi events, by making http requests to the url. According to the source configuration, it analyses metrics from the text response and sends them as Siddhi events through key-value mapping.The user can retrieve metrics of types including, counter, gauge, histogram and summary. Since the source retrieves the metrics from a text response of the target, it is advised to use 'string' as the attribute type for the attributes that correspond to Prometheus metric labels. Further, the Prometheus metric value is passed through the event as 'value'. Therefore, it is advisable to have an attribute with the name 'value' in the stream.  The supported types for the attribute, 'value' are INT, LONG, FLOAT and DOUBLE.  Syntax  @source(type= prometheus , target.url= STRING , scrape.interval= INT , scrape.timeout= INT , scheme= STRING , metric.name= STRING , metric.type= STRING , username= STRING , password= STRING , client.truststore.file= STRING , client.truststore.password= STRING , headers= STRING , job= STRING , instance= STRING , grouping.key= STRING , @map(...)))  QUERY PARAMETERS  \n     \n         Name \n         Description \n         Default Value \n         Possible Data Types \n         Optional \n         Dynamic \n     \n     \n         target.url \n         This property specifies the target url where the Prometheus metrics are exported in text format. \n         \n         STRING \n         No \n         No \n     \n     \n         scrape.interval \n         This property specifies the time interval in seconds within which the source should make an HTTP request to the  provided target url. \n         60 \n         INT \n         Yes \n         No \n     \n     \n         scrape.timeout \n         This property is the time duration in seconds for a scrape request to get timed-out if the server at the url does not respond. \n         10 \n         INT \n         Yes \n         No \n     \n     \n         scheme \n         This property specifies the scheme of the target URL. The supported schemes are 'HTTP' and 'HTTPS'. \n         HTTP \n         STRING \n         Yes \n         No \n     \n     \n         metric.name \n         This property specifies the name of the metrics that are to be fetched. The metric name must match the regex format, i.e., [a-zA-Z_:][a-zA-Z0-9_:]* . \n         Stream name \n         STRING \n         Yes \n         No \n     \n     \n         metric.type \n         This property specifies the type of the Prometheus metric that is required to be fetched.  The supported metric types are 'counter', 'gauge',\" 'histogram' and 'summary'.  \n         \n         STRING \n         No \n         No \n     \n     \n         username \n         This property specifies the username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         STRING \n         Yes \n         No \n     \n     \n         password \n         This property specifies the password that has to be added in the authorization header of the request, if the basic authentication is enabled at the target. It is required to specify both the username and password to enable basic authentication. If one of the parameter is not given by user, then an error is logged in the console. \n         \n         STRING \n         Yes \n         No \n     \n     \n         client.truststore.file \n         The file path to the location of the truststore to which the client needs to send https requests through 'https' protocol. \n         \n         STRING \n         Yes \n         No \n     \n     \n         client.truststore.password \n          The password for client-truststore to send https requests. A custom password can be specified if required.  \n         \n         STRING \n         Yes \n         No \n     \n     \n         headers \n         Headers that should be included as HTTP request headers in the request.  The format of the supported input is as follows,  \"'header1:value1','header2:value2'\" \n         \n         STRING \n         Yes \n         No \n     \n     \n         job \n          This property defines the job name of the exported Prometheus metrics that has to be fetched. \n         \n         STRING \n         Yes \n         No \n     \n     \n         instance \n         This property defines the instance of the exported Prometheus metrics that has to be fetched. \n         \n         STRING \n         Yes \n         No \n     \n     \n         grouping.key \n         This parameter specifies the grouping key of the required metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics. The expected format of the grouping key is as follows:  \"'key1:value1','key2:value2'\" \n         \n         STRING \n         Yes \n         No \n       System Parameters  \n     \n         Name \n         Description \n         Default Value \n         Possible Parameters \n     \n     \n         scrapeInterval \n         The default time interval in seconds for the Prometheus source to make HTTP requests to the target URL. \n         60 \n         Any integer value \n     \n     \n         scrapeTimeout \n         This default time duration (in seconds) for an HTTP request to time-out if the server at the URL does not respond.  \n         10 \n         Any integer value \n     \n     \n         scheme \n         The scheme of the target for Prometheus source to make HTTP requests. The supported schemes are HTTP and HTTPS. \n         HTTP \n         HTTP or HTTPS \n     \n     \n         username \n         The username that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         Any string \n     \n     \n         password \n         The password that has to be added in the authorization header of the HTTP request, if basic authentication is enabled at the target. It is required to specify both username and password to enable basic authentication. If one of the parameter is not given by user then an error is logged in the console. \n         \n         Any string \n     \n     \n         trustStoreFile \n         The default file path to the location of truststore that the client needs to send for HTTPS requests through 'HTTPS' protocol. \n         ${carbon.home}/resources/security/client-truststore.jks \n         Any valid path for the truststore file \n     \n     \n         trustStorePassword \n         The default password for the client-truststore to send HTTPS requests. \n         wso2carbon \n         Any string \n     \n     \n         headers \n         The headers that should be included as HTTP request headers in the scrape request.  The format of the supported input is as follows,  \"'header1:value1','header2:value2'\" \n         \n         Any valid http headers \n     \n     \n         job \n          The default job name of the exported Prometheus metrics that has to be fetched. \n         \n         Any valid job name \n     \n     \n         instance \n         The default instance of the exported Prometheus metrics that has to be fetched. \n         \n         Any valid instance name \n     \n     \n         groupingKey \n         The default grouping key of the required Prometheus metrics in key-value pairs. Grouping key is used if the metrics are exported by Prometheus pushGateway in order to distinguish the metrics from already existing metrics.  The expected format of the grouping key is as follows:  \"'key1:value1','key2:value2'\" \n         \n         Any valid grouping key pairs \n       Examples  EXAMPLE 1  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  counter , metric.name=  sweet_production_counter , @map(type=  keyvalue ))\ndefine stream FooStream1(metric_name string, metric_type string, help string, subtype string, name string, quantity string, value double);  In this example, the prometheus source makes an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus counter metrics with the name, 'sweet_production_counter' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps will have keys and values as follows:  metric_name  -  sweet_production_counter metric_type  -  counter help  -   help_string_of_metric subtype  -  null name -   value_of_label_name quantity -   value_of_label_quantity value -   value_of_metric  EXAMPLE 2  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  summary , metric.name=  sweet_production_summary , @map(type=  keyvalue ))\n define stream FooStream2(metric_name string, metric_type string, help string, subtype string, name string, quantity string, quantile string, value double);  In this example, the prometheus source makes an http request to the 'target.url' and analyses the response. From the analysed response, the source retrieves the Prometheus summary metrics with the name, 'sweet_production_summary' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps have keys and values as follows:  metric_name  -  sweet_production_summary metric_type  -  summary help  -   help_string_of_metric subtype  -   'sum'/'count'/'null' name -   value_of_label_name quantity -   value_of_label_quantity quantile  -   value of the quantile value -   value_of_metric  EXAMPLE 3  @source(type=  prometheus , target.url=  http://localhost:9080/metrics , metric.type=  histogram , metric.name=  sweet_production_histogram , @map(type=  keyvalue ))\ndefine stream FooStream3(metric_name string, metric_type string, help string, subtype string, name string, quantity string, le string, value double);  In this example, the prometheus source will make an http request to the 'target.url' and analyse the response. From the analysed response, the source retrieves the Prometheus histogram metrics with name 'sweet_production_histogram' and converts the filtered metrics into Siddhi events using the key-value mapper. The generated maps will have keys and values as follows,  metric_name  -  sweet_production_histogram metric_type  -  histogram help  -   help_string_of_metric subtype  -   'sum'/'count'/'bucket' name -   value_of_label_name quantity -   value_of_label_quantity le  -   value of the bucket value -   value_of_metric", 
            "title": "prometheus (Source)"
        }, 
        {
            "location": "/api/.md/", 
            "text": "", 
            "title": ""
        }, 
        {
            "location": "/about/license/", 
            "text": "", 
            "title": "License"
        }
    ]
}